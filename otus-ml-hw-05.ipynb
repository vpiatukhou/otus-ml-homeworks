{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "from typing import Optional, Callable\n",
        "from PIL import Image\n",
        "\n",
        "random.seed(123)\n",
        "np.random.seed(123)"
      ],
      "metadata": {
        "id": "om4LPHujadRE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим класс датасета."
      ],
      "metadata": {
        "id": "NWS_G2fcKah6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Задача класса - сформировать список путей к файлам изображений и соответствующих меток, а затем разделить этот список на тренировочный и тестовый датасет\n",
        "class FruitDatasetMetadata():\n",
        "\n",
        "    def __init__(self,\n",
        "                 root='./data/fruit-recognition',\n",
        "                 test_size=0.25,\n",
        "                 dirs_to_exclude={'Total Number of Apples', 'Total Number of Kiwi fruit', 'Guava total', 'guava total final'}) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.img_with_labels_train = []\n",
        "        self.img_with_labels_test = []\n",
        "        self.n_labels = 0\n",
        "\n",
        "        # массив массивов вида [<label>, [<image 1, image 2, ..., image N>]], где\n",
        "        # label - метка класса (число), а image N - путь к файлу изображения\n",
        "        img_grouped_by_labels = []\n",
        "\n",
        "        # Рекурсивно обходим все директории и ищем в них файлы изображений.\n",
        "        # Каждая директория с изображениями - отдельная категория.\n",
        "        self._read_img_recurcive(root, dirs_to_exclude, img_grouped_by_labels)\n",
        "\n",
        "        # делим загруженные данные на тренировочный и тестовый датасеты\n",
        "        for label_with_images in img_grouped_by_labels:\n",
        "            label = label_with_images[0]\n",
        "            images = label_with_images[1]\n",
        "            test_len = int(len(images) * test_size)\n",
        "            test_images = images[:test_len]\n",
        "            train_images = images[test_len:]\n",
        "            for img in test_images:\n",
        "                self.img_with_labels_test.append((img, label))\n",
        "            for img in train_images:\n",
        "                self.img_with_labels_train.append((img, label))\n",
        "\n",
        "    def _read_img_recurcive(self, dir_path: str, dirs_to_exclude: set, img_grouped_by_labels: list):\n",
        "        images = []\n",
        "        with os.scandir(dir_path) as it:\n",
        "            for entry in it:\n",
        "                if entry.is_file():\n",
        "                    if entry.name.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                        images.append(entry.path)\n",
        "                    else:\n",
        "                        print(f'File {entry.name} is not an image.')\n",
        "                elif entry.is_dir():\n",
        "                    if entry.name not in dirs_to_exclude:\n",
        "                        # если директория, то смотрим что внутри\n",
        "                        self._read_img_recurcive(entry.path, dirs_to_exclude, img_grouped_by_labels)\n",
        "        if images:\n",
        "            # метки являются числами, начинающиеся от 0\n",
        "            label = self.n_labels\n",
        "            img_grouped_by_labels.append((label, images))\n",
        "            self.n_labels += 1\n",
        "\n",
        "\n",
        "class FruitDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 img_with_labels: list,\n",
        "                 transform: Optional[Callable]=None) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self._img_with_labels = img_with_labels\n",
        "        self._transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._img_with_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self._img_with_labels[idx]\n",
        "        img_path = row[0]\n",
        "        label = row[1]\n",
        "\n",
        "        with Image.open(img_path) as img:\n",
        "            img.load()\n",
        "            if self._transform:\n",
        "                img = self._transform(img)\n",
        "            return img, label"
      ],
      "metadata": {
        "id": "ZKa1CSlYa4dW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_metadata = FruitDatasetMetadata()\n",
        "\n",
        "transform = EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()\n",
        "train_dataset = FruitDataset(img_with_labels=dataset_metadata.img_with_labels_train, transform=transform)\n",
        "test_dataset = FruitDataset(img_with_labels=dataset_metadata.img_with_labels_test, transform=transform)\n",
        "\n",
        "print(f'Train size: {len(train_dataset)}\\nTest size: {len(test_dataset)}')\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reEq8IZ-a5zC",
        "outputId": "38335d25-a6a3-45d8-9b06-4a6cc8a828b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 33601\n",
            "Test size: 11191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f'Device: {device}')\n",
        "\n",
        "# создаем модель\n",
        "weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
        "model = efficientnet_v2_s(weights=weights)\n",
        "model.to(device)\n",
        "\n",
        "# мы планируем дообучить последний слой модели, поэтому выключаем градиенты, чтобы веса сети не менялись при обучении\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# подстраиваем последний слой под наши данные\n",
        "model.classifier = nn.Sequential(\n",
        "    model.classifier[0],\n",
        "    nn.Linear(model.classifier[1].in_features, dataset_metadata.n_labels)\n",
        ")\n",
        "model.classifier = model.classifier.cuda()"
      ],
      "metadata": {
        "id": "YS17-7Qaa72p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005797e9-51ef-40c3-c17b-580a9af1e14a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 153MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функции train() и test() взяты из материалов лекции."
      ],
      "metadata": {
        "id": "jS-PM6PxGuhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test(dataloader, model, loss_fn, verbose=True, iterations=None):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            if iterations is not None and i >= iterations:\n",
        "                break\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    if verbose:\n",
        "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "KwEbPj8Qa_9p"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
        "\n",
        "for t in range(epochs):\n",
        "    start_time = time.time()\n",
        "    print(f\"Эпоха {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "    end_time = time.time()\n",
        "    print(f'Время: {int(end_time - start_time)} sec')\n",
        "print(\"Обучение завершено.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm2TOB3HbCNZ",
        "outputId": "d66e1767-055d-48fb-e14c-512ea4a7e7ee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1\n",
            "-------------------------------\n",
            "loss: 3.150638  [    0/33601]\n",
            "loss: 0.814392  [ 6400/33601]\n",
            "loss: 0.540098  [12800/33601]\n",
            "loss: 0.339074  [19200/33601]\n",
            "loss: 0.255522  [25600/33601]\n",
            "loss: 0.150367  [32000/33601]\n",
            "Test Error: \n",
            " Accuracy: 97.8%, Avg loss: 0.295674 \n",
            "\n",
            "Время: 716 sec\n",
            "Эпоха 2\n",
            "-------------------------------\n",
            "loss: 0.169050  [    0/33601]\n",
            "loss: 0.142830  [ 6400/33601]\n",
            "loss: 0.182798  [12800/33601]\n",
            "loss: 0.188642  [19200/33601]\n",
            "loss: 0.140549  [25600/33601]\n",
            "loss: 0.142162  [32000/33601]\n",
            "Test Error: \n",
            " Accuracy: 98.7%, Avg loss: 0.164353 \n",
            "\n",
            "Время: 702 sec\n",
            "Эпоха 3\n",
            "-------------------------------\n",
            "loss: 0.118705  [    0/33601]\n",
            "loss: 0.179102  [ 6400/33601]\n",
            "loss: 0.182101  [12800/33601]\n",
            "loss: 0.112246  [19200/33601]\n",
            "loss: 0.087596  [25600/33601]\n",
            "loss: 0.065151  [32000/33601]\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 0.138534 \n",
            "\n",
            "Время: 677 sec\n",
            "Обучение завершено.\n"
          ]
        }
      ]
    }
  ]
}